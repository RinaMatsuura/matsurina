import streamlit as st
import re
import requests
from bs4 import BeautifulSoup
import pandas as pd

st.header("æ¥½å¤©å¸‚å ´ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° ğŸ”", divider="orange")

# å•†å“IDå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
default_id = "354955_10000308"
product_id = st.text_input(
    "æ¥½å¤©ã®å•†å“IDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚åˆ†ã‹ã‚‰ãªã„å ´åˆã¯ã€ŒğŸ’¡ å•†å“IDã£ã¦ã©ã“ã«æ›¸ã„ã¦ã‚ã‚‹ã®ï¼Ÿã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚",
    value=default_id,
    help="æ¥½å¤©å¸‚å ´ã®å•†å“ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒšãƒ¼ã‚¸URLã‹ã‚‰å•†å“IDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
)

# URLã®ç”Ÿæˆ
base_url = f"https://review.rakuten.co.jp/item/1/{product_id}?p="

# ç”Ÿæˆã•ã‚ŒãŸURLã‚’è¡¨ç¤º
st.caption(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡ã®URL: {base_url}1")

# ãƒšãƒ¼ã‚¸æ•°å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
max_pages = st.number_input(
    "ä½•ãƒšãƒ¼ã‚¸ã¾ã§å–å¾—ã—ã¾ã™ã‹ï¼Ÿ",
    min_value=1,
    max_value=100,
    value=3,
    step=1,
    help="å–å¾—ã—ãŸã„ãƒšãƒ¼ã‚¸æ•°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆ1ä»¥ä¸Šã®æ•°å€¤ï¼‰"
)

# å®Ÿè¡Œãƒœã‚¿ãƒ³ã‚’ç›®ç«‹ã¤ã‚ˆã†ã«é…ç½®
st.markdown("---")
col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    start_button = st.button("ğŸš€ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’é–‹å§‹", use_container_width=True)

##########
results = []
##########

if start_button:
    # å®Ÿè¡ŒçŠ¶æ³ã‚’è¡¨ç¤ºã™ã‚‹ã‚³ãƒ³ãƒ†ãƒŠ
    status_container = st.container()
    with status_container:
        st.markdown("### å®Ÿè¡ŒçŠ¶æ³")
        progress_text = st.empty()
        progress_bar = st.progress(0)
        
        try:
            # å‡¦ç†é–‹å§‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            st.info("ğŸ”„ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...")
            
            # æŒ‡å®šã•ã‚ŒãŸãƒšãƒ¼ã‚¸æ•°ã¾ã§ãƒ«ãƒ¼ãƒ—
            for i in range(1, max_pages + 1):
                load_url = base_url + str(i)
                
                # URLã‚¢ã‚¯ã‚»ã‚¹çŠ¶æ³ã‚’è¡¨ç¤º
                progress_text.write(f"ğŸŒ URL: {load_url} ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­...")
                
                # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨­å®šã—ã¦ãƒ–ãƒ­ãƒƒã‚¯ã‚’å›é¿
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }
                
                html = requests.get(load_url, headers=headers)
                soup = BeautifulSoup(html.content, "html.parser")

                review_count = 0
                # ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦ç´ ã®ã‚»ãƒ¬ã‚¯ã‚¿ã‚’ä¿®æ­£
                reviews = soup.select("div[class^='review-detail--']")  # æ–°ã—ã„ã‚¯ãƒ©ã‚¹åã«å¤‰æ›´
                
                # ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒ«ãƒ¼ãƒ—ã‚’çµ‚äº†
                if not reviews:
                    st.warning(f"âš ï¸ ãƒšãƒ¼ã‚¸ {i} ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã“ã“ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¾ã™ã€‚")
                    break
                
                for review in reviews:
                    # ãƒ¬ãƒ“ãƒ¥ãƒ¼æœ¬æ–‡ã‚’å–å¾—
                    review_text = review.select_one("div[class^='review-body--']")  # æ–°ã—ã„ã‚¯ãƒ©ã‚¹åã«å¤‰æ›´
                    if review_text:
                        review_text = review_text.get_text().strip()
                    else:
                        continue
                    
                    # è©•ä¾¡ã‚’å–å¾—
                    score = None
                    score_element = review.select_one("div[class^='review-rating--'] span")  # æ–°ã—ã„ã‚¯ãƒ©ã‚¹åã«å¤‰æ›´
                    if score_element:
                        score_text = score_element.get_text().strip()
                        score_match = re.search(r'(\d+)', score_text)
                        if score_match:
                            score = int(score_match.group(1))
                    
                    # ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼æƒ…å ±ã‚’å–å¾—
                    reviewer_info = review.select_one("div[class^='reviewer-info--']")  # æ–°ã—ã„ã‚¯ãƒ©ã‚¹åã«å¤‰æ›´
                    
                    # å¹´é½¢ã‚’å–å¾—
                    age = None
                    if reviewer_info:
                        info_text = reviewer_info.get_text()
                        age_match = re.search(r'(\d+)ä»£', info_text)
                        if age_match:
                            age = f"{age_match.group(1)}ä»£"
                            # å‰åŠ/å¾ŒåŠã®æƒ…å ±ã‚’å–å¾—
                            if "å‰åŠ" in info_text:
                                age += "å‰åŠ"
                            elif "å¾ŒåŠ" in info_text:
                                age += "å¾ŒåŠ"
                    
                    # æ€§åˆ¥ã‚’å–å¾—
                    gender = None
                    if reviewer_info:
                        if "å¥³æ€§" in info_text:
                            gender = "å¥³æ€§"
                        elif "ç”·æ€§" in info_text:
                            gender = "ç”·æ€§"
                    
                    results.append({
                        "score": score,
                        "age": age,
                        "gender": gender,
                        "comment": review_text
                    })
                    review_count += 1
                    
                # é€²æ—çŠ¶æ³ã‚’æ›´æ–°
                progress = int((i / max_pages) * 100)
                progress_bar.progress(progress)
                progress_text.write(f"âœ… ãƒšãƒ¼ã‚¸ {i}/{max_pages} ã®å‡¦ç†ãŒå®Œäº† (é€²æ—: {progress}%)")
                st.write(f"ğŸ“ {review_count}ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ã—ã¾ã—ãŸ")
                
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆã¨è¡¨ç¤º
            df = pd.DataFrame(results)
            st.success("ğŸ‰ ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            
            # å–å¾—çµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
            st.markdown("### å–å¾—çµæœã‚µãƒãƒªãƒ¼")
            st.write(f"- å®Ÿéš›ã«å–å¾—ã—ãŸãƒšãƒ¼ã‚¸æ•°: {i}ãƒšãƒ¼ã‚¸")
            st.write(f"- ç·ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°: {len(results)}ä»¶")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            st.markdown("### ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            st.data_editor(df)
            
            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            st.markdown("### ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
            csv = df.to_csv(index=False).encode('shift-jis')
            st.download_button(
                label="ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv,
                file_name='rakuten_reviews.csv',
                mime='text/csv',
            )
            
        except Exception as e:
            st.error(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
else:
    st.info("ğŸ‘† ä¸Šã®ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¦ãã ã•ã„")

# ä½¿ã„æ–¹ã®èª¬æ˜
with st.expander("ğŸ’¡ å•†å“IDã£ã¦ã©ã“ã«æ›¸ã„ã¦ã‚ã‚‹ã®ï¼Ÿ"):
    st.write("""
    1. æ¥½å¤©å¸‚å ´ã®å•†å“ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒšãƒ¼ã‚¸ã‚’é–‹ã
    2. URLã®ã€Œitem/1/ã€ã®å¾Œã®æ•°å­—éƒ¨åˆ†ã‚’ã‚³ãƒ”ãƒ¼
    
    ä¾‹ï¼‰https://review.rakuten.co.jp/item/1/354955_10000308
    ã€€ã€€â†’ ã€Œ354955_10000308ã€ãŒå•†å“IDã§ã™
    """)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.sidebar.markdown("---")
st.sidebar.write("ãƒãƒ¼ã‚¸ãƒ§ãƒ³: 1.0.0")
st.sidebar.write("Â© 2024 ã¾ã¤ã‚Šãª") 
